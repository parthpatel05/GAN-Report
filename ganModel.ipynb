{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\parth\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\parth\\AppData\\Local\\Temp\\ipykernel_30308\\3759339556.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "d:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generator\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, latent_dim=100):\n",
    "#         super(Generator, self).__init__()\n",
    "        \n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(latent_dim, 128 * 7 * 7),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Unflatten(1, (128, 7, 7)),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(128, momentum=0.78),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(64, momentum=0.78),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "#             nn.Tanh()  # Output range [-1, 1]\n",
    "#         )\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         img = self.model(z)\n",
    "#         return img\n",
    "\n",
    "\n",
    "# # Discriminator\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "        \n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.25),\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "#             nn.BatchNorm2d(64, momentum=0.82),\n",
    "#             nn.LeakyReLU(0.25),\n",
    "#             nn.Dropout(0.25),\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(128, momentum=0.82),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.25),\n",
    "#             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(256, momentum=0.8),\n",
    "#             nn.LeakyReLU(0.25),\n",
    "#             nn.Dropout(0.25),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(256 * 4 * 4, 1),  # Adjusted for feature map size\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, img):\n",
    "#         validity = self.model(img)\n",
    "#         return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64 * 7 * 7), \n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (64, 7, 7)),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(32, momentum=0.78),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1), \n",
    "            nn.Tanh() \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64, momentum=0.82),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128, momentum=0.8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 1), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_dim = 100\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 10\n",
    "\n",
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Batch 0/938                   Loss D: 0.7403, Loss G: 0.9550\n",
      "Epoch [1/10] Batch 200/938                   Loss D: 0.2647, Loss G: 1.3277\n",
      "Epoch [1/10] Batch 400/938                   Loss D: 0.1894, Loss G: 1.6284\n",
      "Epoch [1/10] Batch 600/938                   Loss D: 0.1473, Loss G: 2.7593\n",
      "Epoch [1/10] Batch 800/938                   Loss D: 0.1305, Loss G: 4.0315\n",
      "Epoch [2/10] Batch 0/938                   Loss D: 0.3091, Loss G: 1.0663\n",
      "Epoch [2/10] Batch 200/938                   Loss D: 0.0843, Loss G: 2.3795\n",
      "Epoch [2/10] Batch 400/938                   Loss D: 0.1115, Loss G: 2.2934\n",
      "Epoch [2/10] Batch 600/938                   Loss D: 0.1574, Loss G: 2.0236\n",
      "Epoch [2/10] Batch 800/938                   Loss D: 0.0736, Loss G: 3.1480\n",
      "Epoch [3/10] Batch 0/938                   Loss D: 0.0633, Loss G: 3.8245\n",
      "Epoch [3/10] Batch 200/938                   Loss D: 0.0699, Loss G: 3.5836\n",
      "Epoch [3/10] Batch 400/938                   Loss D: 0.0647, Loss G: 2.7958\n",
      "Epoch [3/10] Batch 600/938                   Loss D: 0.0863, Loss G: 2.9978\n",
      "Epoch [3/10] Batch 800/938                   Loss D: 0.5898, Loss G: 6.2011\n",
      "Epoch [4/10] Batch 0/938                   Loss D: 0.1026, Loss G: 2.3247\n",
      "Epoch [4/10] Batch 200/938                   Loss D: 0.0664, Loss G: 2.7464\n",
      "Epoch [4/10] Batch 400/938                   Loss D: 0.0558, Loss G: 2.8626\n",
      "Epoch [4/10] Batch 600/938                   Loss D: 0.1080, Loss G: 2.5256\n",
      "Epoch [4/10] Batch 800/938                   Loss D: 0.0776, Loss G: 3.0584\n",
      "Epoch [5/10] Batch 0/938                   Loss D: 0.1175, Loss G: 4.5763\n",
      "Epoch [5/10] Batch 200/938                   Loss D: 0.0988, Loss G: 5.0427\n",
      "Epoch [5/10] Batch 400/938                   Loss D: 0.0547, Loss G: 4.4106\n",
      "Epoch [5/10] Batch 600/938                   Loss D: 0.0465, Loss G: 3.4631\n",
      "Epoch [5/10] Batch 800/938                   Loss D: 0.0745, Loss G: 3.5862\n",
      "Epoch [6/10] Batch 0/938                   Loss D: 1.0842, Loss G: 0.2050\n",
      "Epoch [6/10] Batch 200/938                   Loss D: 0.0499, Loss G: 4.7774\n",
      "Epoch [6/10] Batch 400/938                   Loss D: 0.0968, Loss G: 4.4945\n",
      "Epoch [6/10] Batch 600/938                   Loss D: 0.0324, Loss G: 4.9304\n",
      "Epoch [6/10] Batch 800/938                   Loss D: 0.0904, Loss G: 4.3314\n",
      "Epoch [7/10] Batch 0/938                   Loss D: 0.0727, Loss G: 2.8218\n",
      "Epoch [7/10] Batch 200/938                   Loss D: 0.0341, Loss G: 5.2498\n",
      "Epoch [7/10] Batch 400/938                   Loss D: 0.0754, Loss G: 2.8521\n",
      "Epoch [7/10] Batch 600/938                   Loss D: 0.0734, Loss G: 3.1184\n",
      "Epoch [7/10] Batch 800/938                   Loss D: 0.0683, Loss G: 3.5558\n",
      "Epoch [8/10] Batch 0/938                   Loss D: 0.0431, Loss G: 4.7225\n",
      "Epoch [8/10] Batch 200/938                   Loss D: 0.0132, Loss G: 4.6859\n",
      "Epoch [8/10] Batch 400/938                   Loss D: 0.0643, Loss G: 4.5617\n",
      "Epoch [8/10] Batch 600/938                   Loss D: 0.0803, Loss G: 3.5963\n",
      "Epoch [8/10] Batch 800/938                   Loss D: 0.0501, Loss G: 3.3743\n",
      "Epoch [9/10] Batch 0/938                   Loss D: 0.1871, Loss G: 1.8872\n",
      "Epoch [9/10] Batch 200/938                   Loss D: 0.0831, Loss G: 6.9652\n",
      "Epoch [9/10] Batch 400/938                   Loss D: 0.0631, Loss G: 3.1718\n",
      "Epoch [9/10] Batch 600/938                   Loss D: 0.0582, Loss G: 4.5271\n",
      "Epoch [9/10] Batch 800/938                   Loss D: 0.0201, Loss G: 4.1585\n",
      "Epoch [10/10] Batch 0/938                   Loss D: 0.1741, Loss G: 1.7171\n",
      "Epoch [10/10] Batch 200/938                   Loss D: 0.0305, Loss G: 4.1746\n",
      "Epoch [10/10] Batch 400/938                   Loss D: 0.0400, Loss G: 3.4543\n",
      "Epoch [10/10] Batch 600/938                   Loss D: 0.0373, Loss G: 3.5400\n",
      "Epoch [10/10] Batch 800/938                   Loss D: 0.0591, Loss G: 5.8647\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        \n",
    "        real_labels = torch.ones(imgs.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(imgs.size(0), 1).to(device)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # predict\n",
    "        z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # loss gen\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # loss disc\n",
    "        real_loss = adversarial_loss(discriminator(imgs.to(device)), real_labels)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake_labels)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # backwarse\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
    "                  Loss D: {d_loss:.4f}, Loss G: {g_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m grid \u001b[38;5;241m=\u001b[39m make_grid(generated_images, nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   3541\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   3543\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3561\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[1;32m-> 3562\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3581\u001b[0m     sci(__ret)\n\u001b[0;32m   3582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:1486\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1491\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1492\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1493\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:690\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_normalize_image_array\u001b[39m(A):\n\u001b[0;32m    686\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m    Check validity of image-like input *A* and normalize it to a format suitable for\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m    Image subclasses.\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 690\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    692\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    693\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\cbook.py:733\u001b[0m, in \u001b[0;36msafe_masked_invalid\u001b[1;34m(x, copy)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_masked_invalid\u001b[39m(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 733\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[0;32m    737\u001b[0m         \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n\u001b[0;32m    738\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mbyteswap(inplace\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32md:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create images\n",
    "noise = torch.randn(16, latent_dim).to(device)\n",
    "generated_images = generator(noise).view(-1, 1, 28, 28).cpu().detach()\n",
    "grid = make_grid(generated_images, nrow=4, normalize=True)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\AppData\\Local\\Temp\\ipykernel_13952\\1611587311.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  generator.load_state_dict(torch.load(\"generator.pth\"))\n",
      "C:\\Users\\parth\\AppData\\Local\\Temp\\ipykernel_13952\\1611587311.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  discriminator.load_state_dict(torch.load(\"discriminator.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.load_state_dict(torch.load(\"generator.pth\"))\n",
    "discriminator.load_state_dict(torch.load(\"discriminator.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
